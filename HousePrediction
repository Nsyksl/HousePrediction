# Gerekli kütüphanelerin yüklenmesi

import matplotlib.pyplot as plt
import pandas as pd 
import numpy as np
import seaborn as sns

import warnings
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, mean_squared_error, RocCurveDisplay #plot_roc_curve
from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.exceptions import ConvergenceWarning

from xgboost import XGBRegressor
# !pip install catboost
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor

# Çıktılar ile ilgili gereken ayarlamalar

pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", None)
pd.set_option("display.width", 500)
pd.set_option("display.float_format", lambda x: "%.3f" % x)


# Train ve Test setlerinin yüklenmesi 
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")


test['type'] = "test"
train['type'] = "train"

# Train ve Test setinin birleştirilmesi
df = pd.concat([test, train])

df.drop("type", axis=1, inplace=True)

def grab_col_names(dataframe, cat_th=10, car_th=20):
  """
  ******* 
  Parametreler
  ------
    dataframe : dataframe
       Değişken isimleri alınmak istenen DataFrame'dir.

    cat_th :  int / float
        Numerik fakat kategorik olan değişkenler için sınıf eşiği 
    
    car_th : int / float
      Kategorik fakat kardinal olan değişkenler için sınıf eşiği

    
  Returns 
   ------
    cath_cols : list
         Kategorik değişken listesi
    num_cols : list
        Numerik değişken listesi
    cat_but_car : 
        Kategorik gözüken fakat kardinal olan değişken listesi

    
  Notes :
  ----- 
    cath_cols + num_cols + cat_but_car = Toplam Değişken Sayısı
    -----------
    """
  cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == "O"]
  num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and 
                 dataframe[col].dtypes != "O"]
  cat_but_car = [col for col in dataframe.columns if
                 dataframe[col].nunique() > car_th and dataframe[col].dtypes == "O"]
  cat_cols = cat_cols + num_but_cat
  cat_cols = [col for col in cat_cols if col not in cat_but_car]

  num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != "O"]
  num_cols = [col for col in num_cols if col not in num_but_cat]


  print(f"Obervations: {dataframe.shape[0]}")
  print(f"Variables: {dataframe.shape[1]}")
  print(f"cat_cols: {len(cat_cols)}")
  print(f"num_cols: {len(num_cols)}")
  print(f"cat_but_car: {len(cat_but_car)}")
  print(f"num_but_cat: {len(num_but_cat)}")

  return cat_cols, num_cols, cat_but_car
  
cat_cols, num_cols, cat_but_car = grab_col_names(df)

# Kategorik Değişken Analizi
def cat_summary(dataframe, col_name, plot=False):
  print(pd.DataFrame({col_name : dataframe[col_name].value_counts(),
                      "Ratio" : 100* dataframe[col_name].value_counts() / len(dataframe)}))
  print("###########################")
  if plot:
    sns.countplot(x=dataframe[col_name], data=dataframe)
    
for col in cat_cols:
  print(col, cat_summary(df, col, True))
  
  
# Numerik Değişken Analizi
def num_summary(dataframe, num_cols, plot=False):
  quantiles = [0.05, 0.10, 0.25, 0.50, 0.60, 0.75, 0.90, 0.95, 0.99]
  print(dataframe[num_cols].describe(quantiles).T)
  

  if plot:
    dataframe[num_cols].hist(bins=20)
    plt.xlabel(num_cols)
    plt.title(num_cols)
    plt.show()

for col in num_cols:
  print(col, num_summary(df, col, True))

# Hedef değişken kırılımında numerik değişkenlerin analizi
def target_summary_with_num(dataframe, target, num_cols):
  print(dataframe.groupby(target).agg({num_cols : "mean"}), end="\n\n\n")
  
# Hedef değişken kırılımında kategorik değişkenlerin analizi
def target_summary_with_cat(dataframe, target, cat_cols):
  print(pd.DataFrame({"Target_Mean": dataframe.groupby(cat_cols)[target].mean()}), end="\n\n\n")
  
  
for col in cat_cols:
  target_summary_with_cat(df, "SalePrice", col)
  
# Bağımlı Değişkenin Analizi

df["SalePrice"].hist(bins=100)

# Bağımlı Değişkenin Logaritmik Analizi

np.log1p(df["SalePrice"]).hist(bins=50)

# Numerik Değişkenlerin Korelasyon Analizi
corr = df[num_cols].corr()
sns.set(rc={"figure.figsize" : (12,12)})
sns.heatmap(corr, annot=True)

# Eşik Değerlerini Belirleyen Fonksiyon
def outlier_treshold(dataframe, col_name, q1=0.05, q3=0.95):
  quantile1 = dataframe[col_name].quantile(q1)
  quantile3 = dataframe[col_name].quantile(q3) 
  ıqr = quantile3 - quantile1
  up_limit = quantile3 + 1.5 * ıqr
  low_limit = quantile1 - 1.5 * ıqr
  return low_limit, up_limit

# Aykırı Değerin var olup olmamasını kontrol eden fonksiyon
def check_outlier(dataframe, col_name):
  low, up = outlier_treshold(dataframe, col_name)

  if dataframe[(dataframe[col_name] > up) | (dataframe[col_name] < low) ].any(axis=None):
    return True
  else :
    return False

  
 for col in num_cols:
  print(col, check_outlier(df, col))
  
def replace_with_tresholds(dataframe, col_name):
 low, up = outlier_treshold(dataframe, col_name)
 dataframe.loc[(dataframe[col_name] < low), col_name] = low 
 dataframe.loc[(dataframe[col_name] > up), col_name] = up
 
for col in num_cols:
 if col != "SalePrice":
   replace_with_tresholds(df, col)
    

def missing_value(dataframe, na_name=False):
  nan_cols = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0 ]
  n_miss = dataframe[nan_cols].isnull().sum().sort_values(ascending=False)
  ratio = (dataframe[nan_cols].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)
  missing_df = pd.concat([n_miss, np.round(ratio,2)], axis=1, keys=["n_miss", "ratio"])
  print(missing_df)

  if na_name:
    return nan_cols

nan_cols = missing_value(df, True)

# ['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SalePrice']


no_cols = ["Alley", "BsmtQual", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "FireplaceQu", "GarageType",
          "GarageFinish", "GarageQual", "GarageCond", "PoolQC", "Fence", "MiscFeature"]
# Bazı değişkenlerin boş değer olarak algılamasının sebebi aslında evde o özelliğin bulunmamasından kaynaklı. Bu NaN değerleri No ile değiştirdik.
for col in no_cols:
  df[col].fillna("No", inplace=True)
  

def quick_missing_imp(data, num_method="median", cat_length=20, target="SalePrice"):
  variables_with_na = [col for col in data.columns if data[col].isnull().sum() > 0]

  temp_target = data[target]
  print("#BEFORE")
  print(data[variables_with_na].isnull().sum(), "\n\n")

  # Değişken object ve sınıf sayısı cat_length eşit veya altındaysa boş değerleri mode ile doldurur

  data = data.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == "O" and len(x.unique()) <= cat_length) else x, axis=0)  

  # num_method = mean ise object olmanları mean ile dolduruyor. 

  if num_method=="mean":
    data = data.apply(lambda x: x.fillna(x.mean()) if x.dtype != "O" else x, axis=0)


  elif num_method == "median":
    data = data.apply(lambda x: x.fillna(x.median()) if x.dtype != "O" else x, axis=0)

  data[target] = temp_target

  print("# AFTER \n Imputaion method is "+ num_method.upper() + " for numeric variables", "\n")
  print(data[variables_with_na].isnull().sum(), "\n\n" )

  return data

df = quick_missing_imp(df)


def rare_analyser(dataframe, target, cat_cols):
  for col in cat_cols:
    print(col, ":", len(dataframe[col].value_counts()))
    print(pd.DataFrame({"Count": dataframe[col].value_counts(),
                        "ratio": dataframe[col].value_counts() / len(dataframe),
                        "Target_Mean": dataframe.groupby(col)[target].mean()}), end="\n\n\n")


def rare_encoder(dataframe, rare_perc):
  temp_df = dataframe.copy()
  rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == "O" and (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis=None)]

  for var in rare_columns:
    tmp = temp_df[var].value_counts() / len(temp_df)
    rare_labels = tmp[tmp < rare_perc].index
    temp_df[var] = np.where(temp_df[var].isin(rare_labels), "Rare", temp_df[var])


  return temp_df
  
# Nadir Değişken Analizi
rare_analyser(df, "SalePrice", cat_cols)


rare_encoder(df, 0.01).tail()

# Yeni Değişkenlerin Oluşturulması

df["New_Total_Floor"] = df["1stFlrSF"] + df["2ndFlrSF"]
df["New_Total_Porch"] = df["OpenPorchSF"] + df["EnclosedPorch"] + df["3SsnPorch"] + df["ScreenPorch"]
df["New_Garage*Griv"] = df["GarageArea"] * df["GrLivArea"]
df["New_TotRmsAbvGrd+Bath"] = df["TotRmsAbvGrd"] + df["FullBath"] + df["HalfBath"]


df["New_Total_Qual"] = df[["OverallQual", "OverallCond", "ExterQual", "ExterCond", "BsmtCond",
                           "BsmtFinType1", "BsmtFinType2", "HeatingQC", "KitchenQual", 
                           "Functional", "FireplaceQu", "GarageQual", "GarageCond", "Fence"]].sum(axis=1)
df["New_OverallGrade"] = df["OverallQual"] * df["OverallCond"]
df["New_TotalBsmtFin"] = df["BsmtFinSF1"] + df["BsmtFinSF2"]
df["New_Total_house_area"] = df["New_TotalBsmtFin"] + df["New_Total_Floor"] 
df["New_Lot_Ratio"] = df["GrLivArea"] / df["LotArea"]
df["New_Ratio_Area"] = df["New_Total_house_area"] / df["LotArea"]
df["New_GarageLotRatio"] = df["GarageArea"] / df["LotArea"]
df["New_RestorationAge"] = df["YrSold"]- df["YearRemodAdd"]

drop_list = ["Alley", "Street", "LandContour", "Utilities", "LandSlope", "Heating", "PoolQC", "MiscFeature", "Neighborhood"]
df.drop(drop_list, axis=1, inplace=True)

# LABEL ENCODİNG & ONE HOT ENCODİNG İŞLEMLERİ

cat_cols, num_cols, cat_but_car = grab_col_names(df)

def binary_cols(dataframe):
  binary_cols = []
  for col in dataframe.columns:
    if dataframe[col].dtype not in [int, float] and df[col].nunique() == 2:
      binary_cols.append(col)
  return binary_cols
  
binary_cols = binary_cols(df)


def label_encoder(dataframe, binary_cal):
  label_encoder = LabelEncoder()
  dataframe[binary_cal] = label_encoder.fit_transform(dataframe[binary_cal])
  return dataframe

for col in binary_cols:
  label_encoder(df, col)
  
def one_hot_encoder(dataframe, categorical_cols, drop_first=True):
  dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)
  return dataframe
  
 df = one_hot_encoder(df, cat_cols)
 
 # Modelleme Aşaması
 
train_df = df[df["SalePrice"].notnull()]
test_df = df[df["SalePrice"].isnull()]

y = train_df["SalePrice"]
X = train_df.drop(["SalePrice", "Id"] ,axis=1)

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=17)

models = [("LR", LogisticRegression()),
          ("KNN", KNeighborsRegressor()), 
          ("CART", DecisionTreeRegressor()), 
          ("RF", RandomForestRegressor()), 
          ("GBM", GradientBoostingRegressor()), 
          ("XGBoost", XGBRegressor(objective="reg:squarederror")), 
          ("LightGBM", LGBMRegressor())]
          
          
for name, regressor in models:
  rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=5, scoring= "neg_mean_squared_error")))
  print(f"RMSE :  {round(rmse,4)} ({name})")



# RMSE :  62938.3754 (LR)
# RMSE :  52204.1004 (KNN)
# RMSE :  46069.1482 (CART)
# RMSE :  29898.3606 (RF)
# RMSE :  26721.8739 (GBM)
# RMSE :  31337.1106 (XGBoost)
# RMSE :  29781.9582 (LightGBM)

 
print("Hedef Değişken Ortalaması : " +str(df["SalePrice"].mean())  + "\n" + "Hedef Değişken Standart Sapması  :  "+ str(df["SalePrice"].std()))

# Hedef Değişken Ortalaması : 180921.19589041095
# Hedef Değişken Standart Sapması  :  79442.50288288662


train_df = df[df["SalePrice"].notnull()]
test_df = df[df["SalePrice"].isnull()]

y = np.log1p(train_df["SalePrice"])
X = train_df.drop(["SalePrice", "Id"] ,axis=1)

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=17)

lgbm = LGBMRegressor().fit(X_train, y_train)
y_pred = lgbm.predict(X_test)

y = np.expm1(y)

new_y = np.expm1(y_pred)

new_y_test = np.expm1(y_test)

np.sqrt(mean_squared_error(new_y_test, new_y))


# ESKİ RMSE :  29781.9582 (LightGBM)



# YENİ RMSE   :   25032.55220143651  


# Bunun sebebi Logaritmik dönüşümle birlikte modeli uygulamamız oldu. Çünkü diğer türlü bir normalizasyon işlemi olmadan tahmin etmesi daha güç hale geliyor.

lgbm_model = LGBMRegressor(random_state=46)
rmse = np.mean(np.sqrt(-cross_val_score(lgbm_model, X, y, cv=5, scoring= "neg_mean_squared_error")))

lgbm_param = {"learning_rate" : [0.01, 0.1],
              "n_estimators" : [500,1500],
              
              }
              
lgbm_gs_best = GridSearchCV(lgbm_model, 
                            lgbm_param,
                            cv=3,
                            n_jobs = -1,
                            verbose=True).fit(X_train, y_train)
 
final_model = lgbm_model.set_params(**lgbm_gs_best.best_params_).fit(X,y)
rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=5, scoring= "neg_mean_squared_error")))

rmse
# 0.1357361581316574

# Önem arz eden değişkenler

def plot_importance(model, features, num=len(X), save=False):
  feature_imp = pd.DataFrame({"Value" : model.feature_importances_, "Feature" : features.columns })
  plt.figure(figsize= (20,20))
  sns.set(font_scale=1)
  sns.barplot(x="Value", y="Feature", data=feature_imp.sort_values(by="Value", ascending=False)[0:num])

  plt.title("Features")
  plt.tight_layout()
  plt.show()
  if save:
    plt.savefig("importances.png")

plot_importance(final_model, X)

model = LGBMRegressor()
model.fit(X, y)

predictions = model.predict(test_df.drop(["Id", "SalePrice"], axis=1))
dic = {"Id": test_df.index, "SalePrice" : predictions }
dfSubmission = pd.DataFrame(dic)
dfSubmission.to_csv("House_PredictionPrice.csv", index=False)

predictionprice = pd.read_csv("House_PredictionPrice.csv")
predictionprice.head()
 
